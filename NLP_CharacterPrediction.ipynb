{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swordman08/NLP-with-LSTM/blob/main/NLP_CharacterPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hfyzijgapPp"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import re\n",
        "import requests\n",
        "import io\n",
        "# book we are using (utf-8 format) https://www.gutenberg.org/cache/epub/2600/pg2600.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uK0OS4Rd3UN",
        "outputId": "02f7403b-be7a-456b-fe69-4ae37d8cf881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trimmed Part (last 18830 characters):\n",
            " ** end of the project gutenberg ebook war and peace ***\r\n",
            "\r\n",
            "\r\n",
            "    \r\n",
            "\r\n",
            "updated editions will replace the previous one—the old editions will\r\n",
            "be renamed.\r\n",
            "\r\n",
            "creating the works from print editions not protected by u.s. copyright\r\n",
            "law means that no one owns a united states copyright in these works,\r\n",
            "so the foundation (and you!) can copy and distribute it in the united\r\n",
            "states without permission and without paying copyright\r\n",
            "royalties. special rules, set forth in the general terms of use part\r\n",
            "of this license, apply to copying and distributing project\r\n",
            "gutenberg™ electronic works to protect the project gutenberg™\r\n",
            "concept and trademark. project gutenberg is a registered trademark,\r\n",
            "and may not be used if you charge for an ebook, except by following\r\n",
            "the terms of the trademark license, including paying royalties for use\r\n",
            "of the project gutenberg trademark. if you do not charge anything for\r\n",
            "copies of this ebook, complying with the trademark license is very\r\n",
            "easy. you may use this ebook for nearly any purpose such as creation\r\n",
            "of derivative works, reports, performances and research. project\r\n",
            "gutenberg ebooks may be modified and printed and given away—you may\r\n",
            "do practically anything in the united states with ebooks not protected\r\n",
            "by u.s. copyright law. redistribution is subject to the trademark\r\n",
            "license, especially commercial redistribution.\r\n",
            "\r\n",
            "\r\n",
            "start: full license\r\n",
            "\r\n",
            "the full project gutenberg license\r\n",
            "\r\n",
            "please read this before you distribute or use this work\r\n",
            "\r\n",
            "to protect the project gutenberg™ mission of promoting the free\r\n",
            "distribution of electronic works, by using or distributing this work\r\n",
            "(or any other work associated in any way with the phrase “project\r\n",
            "gutenberg”), you agree to comply with all the terms of the full\r\n",
            "project gutenberg™ license available with this file or online at\r\n",
            "www.gutenberg.org/license.\r\n",
            "\r\n",
            "section 1. general terms of use and redistributing project gutenberg™\r\n",
            "electronic works\r\n",
            "\r\n",
            "1.a. by reading or using any part of this project gutenberg™\r\n",
            "electronic work, you indicate that you have read, understand, agree to\r\n",
            "and accept all the terms of this license and intellectual property\r\n",
            "(trademark/copyright) agreement. if you do not agree to abide by all\r\n",
            "the terms of this agreement, you must cease using and return or\r\n",
            "destroy all copies of project gutenberg™ electronic works in your\r\n",
            "possession. if you paid a fee for obtaining a copy of or access to a\r\n",
            "project gutenberg™ electronic work and you do not agree to be bound\r\n",
            "by the terms of this agreement, you may obtain a refund from the person\r\n",
            "or entity to whom you paid the fee as set forth in paragraph 1.e.8.\r\n",
            "\r\n",
            "1.b. “project gutenberg” is a registered trademark. it may only be\r\n",
            "used on or associated in any way with an electronic work by people who\r\n",
            "agree to be bound by the terms of this agreement. there are a few\r\n",
            "things that you can do with most project gutenberg™ electronic works\r\n",
            "even without complying with the full terms of this agreement. see\r\n",
            "paragraph 1.c below. there are a lot of things you can do with project\r\n",
            "gutenberg™ electronic works if you follow the terms of this\r\n",
            "agreement and help preserve free future access to project gutenberg™\r\n",
            "electronic works. see paragraph 1.e below.\r\n",
            "\r\n",
            "1.c. the project gutenberg literary archive foundation (“the\r\n",
            "foundation” or pglaf), owns a compilation copyright in the collection\r\n",
            "of project gutenberg™ electronic works. nearly all the individual\r\n",
            "works in the collection are in the public domain in the united\r\n",
            "states. if an individual work is unprotected by copyright law in the\r\n",
            "united states and you are located in the united states, we do not\r\n",
            "claim a right to prevent you from copying, distributing, performing,\r\n",
            "displaying or creating derivative works based on the work as long as\r\n",
            "all references to project gutenberg are removed. of course, we hope\r\n",
            "that you will support the project gutenberg™ mission of promoting\r\n",
            "free access to electronic works by freely sharing project gutenberg™\r\n",
            "works in compliance with the terms of this agreement for keeping the\r\n",
            "project gutenberg™ name associated with the work. you can easily\r\n",
            "comply with the terms of this agreement by keeping this work in the\r\n",
            "same format with its attached full project gutenberg™ license when\r\n",
            "you share it without charge with others.\r\n",
            "\r\n",
            "1.d. the copyright laws of the place where you are located also govern\r\n",
            "what you can do with this work. copyright laws in most countries are\r\n",
            "in a constant state of change. if you are outside the united states,\r\n",
            "check the laws of your country in addition to the terms of this\r\n",
            "agreement before downloading, copying, displaying, performing,\r\n",
            "distributing or creating derivative works based on this work or any\r\n",
            "other project gutenberg™ work. the foundation makes no\r\n",
            "representations concerning the copyright status of any work in any\r\n",
            "country other than the united states.\r\n",
            "\r\n",
            "1.e. unless you have removed all references to project gutenberg:\r\n",
            "\r\n",
            "1.e.1. the following sentence, with active links to, or other\r\n",
            "immediate access to, the full project gutenberg™ license must appear\r\n",
            "prominently whenever any copy of a project gutenberg™ work (any work\r\n",
            "on which the phrase “project gutenberg” appears, or with which the\r\n",
            "phrase “project gutenberg” is associated) is accessed, displayed,\r\n",
            "performed, viewed, copied or distributed:\r\n",
            "\r\n",
            "    this ebook is for the use of anyone anywhere in the united states and most\r\n",
            "    other parts of the world at no cost and with almost no restrictions\r\n",
            "    whatsoever. you may copy it, give it away or re-use it under the terms\r\n",
            "    of the project gutenberg license included with this ebook or online\r\n",
            "    at www.gutenberg.org. if you\r\n",
            "    are not located in the united states, you will have to check the laws\r\n",
            "    of the country where you are located before using this ebook.\r\n",
            "  \r\n",
            "1.e.2. if an individual project gutenberg™ electronic work is\r\n",
            "derived from texts not protected by u.s. copyright law (does not\r\n",
            "contain a notice indicating that it is posted with permission of the\r\n",
            "copyright holder), the work can be copied and distributed to anyone in\r\n",
            "the united states without paying any fees or charges. if you are\r\n",
            "redistributing or providing access to a work with the phrase “project\r\n",
            "gutenberg” associated with or appearing on the work, you must comply\r\n",
            "either with the requirements of paragraphs 1.e.1 through 1.e.7 or\r\n",
            "obtain permission for the use of the work and the project gutenberg™\r\n",
            "trademark as set forth in paragraphs 1.e.8 or 1.e.9.\r\n",
            "\r\n",
            "1.e.3. if an individual project gutenberg™ electronic work is posted\r\n",
            "with the permission of the copyright holder, your use and distribution\r\n",
            "must comply with both paragraphs 1.e.1 through 1.e.7 and any\r\n",
            "additional terms imposed by the copyright holder. additional terms\r\n",
            "will be linked to the project gutenberg™ license for all works\r\n",
            "posted with the permission of the copyright holder found at the\r\n",
            "beginning of this work.\r\n",
            "\r\n",
            "1.e.4. do not unlink or detach or remove the full project gutenberg™\r\n",
            "license terms from this work, or any files containing a part of this\r\n",
            "work or any other work associated with project gutenberg™.\r\n",
            "\r\n",
            "1.e.5. do not copy, display, perform, distribute or redistribute this\r\n",
            "electronic work, or any part of this electronic work, without\r\n",
            "prominently displaying the sentence set forth in paragraph 1.e.1 with\r\n",
            "active links or immediate access to the full terms of the project\r\n",
            "gutenberg™ license.\r\n",
            "\r\n",
            "1.e.6. you may convert to and distribute this work in any binary,\r\n",
            "compressed, marked up, nonproprietary or proprietary form, including\r\n",
            "any word processing or hypertext form. however, if you provide access\r\n",
            "to or distribute copies of a project gutenberg™ work in a format\r\n",
            "other than “plain vanilla ascii” or other format used in the official\r\n",
            "version posted on the official project gutenberg™ website\r\n",
            "(www.gutenberg.org), you must, at no additional cost, fee or expense\r\n",
            "to the user, provide a copy, a means of exporting a copy, or a means\r\n",
            "of obtaining a copy upon request, of the work in its original “plain\r\n",
            "vanilla ascii” or other form. any alternate format must include the\r\n",
            "full project gutenberg™ license as specified in paragraph 1.e.1.\r\n",
            "\r\n",
            "1.e.7. do not charge a fee for access to, viewing, displaying,\r\n",
            "performing, copying or distributing any project gutenberg™ works\r\n",
            "unless you comply with paragraph 1.e.8 or 1.e.9.\r\n",
            "\r\n",
            "1.e.8. you may charge a reasonable fee for copies of or providing\r\n",
            "access to or distributing project gutenberg™ electronic works\r\n",
            "provided that:\r\n",
            "\r\n",
            "    • you pay a royalty fee of 20% of the gross profits you derive from\r\n",
            "        the use of project gutenberg™ works calculated using the method\r\n",
            "        you already use to calculate your applicable taxes. the fee is owed\r\n",
            "        to the owner of the project gutenberg™ trademark, but he has\r\n",
            "        agreed to donate royalties under this paragraph to the project\r\n",
            "        gutenberg literary archive foundation. royalty payments must be paid\r\n",
            "        within 60 days following each date on which you prepare (or are\r\n",
            "        legally required to prepare) your periodic tax returns. royalty\r\n",
            "        payments should be clearly marked as such and sent to the project\r\n",
            "        gutenberg literary archive foundation at the address specified in\r\n",
            "        section 4, “information about donations to the project gutenberg\r\n",
            "        literary archive foundation.”\r\n",
            "    \r\n",
            "    • you provide a full refund of any money paid by a user who notifies\r\n",
            "        you in writing (or by e-mail) within 30 days of receipt that s/he\r\n",
            "        does not agree to the terms of the full project gutenberg™\r\n",
            "        license. you must require such a user to return or destroy all\r\n",
            "        copies of the works possessed in a physical medium and discontinue\r\n",
            "        all use of and all access to other copies of project gutenberg™\r\n",
            "        works.\r\n",
            "    \r\n",
            "    • you provide, in accordance with paragraph 1.f.3, a full refund of\r\n",
            "        any money paid for a work or a replacement copy, if a defect in the\r\n",
            "        electronic work is discovered and reported to you within 90 days of\r\n",
            "        receipt of the work.\r\n",
            "    \r\n",
            "    • you comply with all other terms of this agreement for free\r\n",
            "        distribution of project gutenberg™ works.\r\n",
            "    \r\n",
            "\r\n",
            "1.e.9. if you wish to charge a fee or distribute a project\r\n",
            "gutenberg™ electronic work or group of works on different terms than\r\n",
            "are set forth in this agreement, you must obtain permission in writing\r\n",
            "from the project gutenberg literary archive foundation, the manager of\r\n",
            "the project gutenberg™ trademark. contact the foundation as set\r\n",
            "forth in section 3 below.\r\n",
            "\r\n",
            "1.f.\r\n",
            "\r\n",
            "1.f.1. project gutenberg volunteers and employees expend considerable\r\n",
            "effort to identify, do copyright research on, transcribe and proofread\r\n",
            "works not protected by u.s. copyright law in creating the project\r\n",
            "gutenberg™ collection. despite these efforts, project gutenberg™\r\n",
            "electronic works, and the medium on which they may be stored, may\r\n",
            "contain “defects,” such as, but not limited to, incomplete, inaccurate\r\n",
            "or corrupt data, transcription errors, a copyright or other\r\n",
            "intellectual property infringement, a defective or damaged disk or\r\n",
            "other medium, a computer virus, or computer codes that damage or\r\n",
            "cannot be read by your equipment.\r\n",
            "\r\n",
            "1.f.2. limited warranty, disclaimer of damages - except for the “right\r\n",
            "of replacement or refund” described in paragraph 1.f.3, the project\r\n",
            "gutenberg literary archive foundation, the owner of the project\r\n",
            "gutenberg™ trademark, and any other party distributing a project\r\n",
            "gutenberg™ electronic work under this agreement, disclaim all\r\n",
            "liability to you for damages, costs and expenses, including legal\r\n",
            "fees. you agree that you have no remedies for negligence, strict\r\n",
            "liability, breach of warranty or breach of contract except those\r\n",
            "provided in paragraph 1.f.3. you agree that the foundation, the\r\n",
            "trademark owner, and any distributor under this agreement will not be\r\n",
            "liable to you for actual, direct, indirect, consequential, punitive or\r\n",
            "incidental damages even if you give notice of the possibility of such\r\n",
            "damage.\r\n",
            "\r\n",
            "1.f.3. limited right of replacement or refund - if you discover a\r\n",
            "defect in this electronic work within 90 days of receiving it, you can\r\n",
            "receive a refund of the money (if any) you paid for it by sending a\r\n",
            "written explanation to the person you received the work from. if you\r\n",
            "received the work on a physical medium, you must return the medium\r\n",
            "with your written explanation. the person or entity that provided you\r\n",
            "with the defective work may elect to provide a replacement copy in\r\n",
            "lieu of a refund. if you received the work electronically, the person\r\n",
            "or entity providing it to you may choose to give you a second\r\n",
            "opportunity to receive the work electronically in lieu of a refund. if\r\n",
            "the second copy is also defective, you may demand a refund in writing\r\n",
            "without further opportunities to fix the problem.\r\n",
            "\r\n",
            "1.f.4. except for the limited right of replacement or refund set forth\r\n",
            "in paragraph 1.f.3, this work is provided to you ‘as-is’, with no\r\n",
            "other warranties of any kind, express or implied, including but not\r\n",
            "limited to warranties of merchantability or fitness for any purpose.\r\n",
            "\r\n",
            "1.f.5. some states do not allow disclaimers of certain implied\r\n",
            "warranties or the exclusion or limitation of certain types of\r\n",
            "damages. if any disclaimer or limitation set forth in this agreement\r\n",
            "violates the law of the state applicable to this agreement, the\r\n",
            "agreement shall be interpreted to make the maximum disclaimer or\r\n",
            "limitation permitted by the applicable state law. the invalidity or\r\n",
            "unenforceability of any provision of this agreement shall not void the\r\n",
            "remaining provisions.\r\n",
            "\r\n",
            "1.f.6. indemnity - you agree to indemnify and hold the foundation, the\r\n",
            "trademark owner, any agent or employee of the foundation, anyone\r\n",
            "providing copies of project gutenberg™ electronic works in\r\n",
            "accordance with this agreement, and any volunteers associated with the\r\n",
            "production, promotion and distribution of project gutenberg™\r\n",
            "electronic works, harmless from all liability, costs and expenses,\r\n",
            "including legal fees, that arise directly or indirectly from any of\r\n",
            "the following which you do or cause to occur: (a) distribution of this\r\n",
            "or any project gutenberg™ work, (b) alteration, modification, or\r\n",
            "additions or deletions to any project gutenberg™ work, and (c) any\r\n",
            "defect you cause.\r\n",
            "\r\n",
            "section 2. information about the mission of project gutenberg™\r\n",
            "\r\n",
            "project gutenberg™ is synonymous with the free distribution of\r\n",
            "electronic works in formats readable by the widest variety of\r\n",
            "computers including obsolete, old, middle-aged and new computers. it\r\n",
            "exists because of the efforts of hundreds of volunteers and donations\r\n",
            "from people in all walks of life.\r\n",
            "\r\n",
            "volunteers and financial support to provide volunteers with the\r\n",
            "assistance they need are critical to reaching project gutenberg™’s\r\n",
            "goals and ensuring that the project gutenberg™ collection will\r\n",
            "remain freely available for generations to come. in 2001, the project\r\n",
            "gutenberg literary archive foundation was created to provide a secure\r\n",
            "and permanent future for project gutenberg™ and future\r\n",
            "generations. to learn more about the project gutenberg literary\r\n",
            "archive foundation and how your efforts and donations can help, see\r\n",
            "sections 3 and 4 and the foundation information page at www.gutenberg.org.\r\n",
            "\r\n",
            "section 3. information about the project gutenberg literary archive foundation\r\n",
            "\r\n",
            "the project gutenberg literary archive foundation is a non-profit\r\n",
            "501(c)(3) educational corporation organized under the laws of the\r\n",
            "state of mississippi and granted tax exempt status by the internal\r\n",
            "revenue service. the foundation’s ein or federal tax identification\r\n",
            "number is 64-6221541. contributions to the project gutenberg literary\r\n",
            "archive foundation are tax deductible to the full extent permitted by\r\n",
            "u.s. federal laws and your state’s laws.\r\n",
            "\r\n",
            "the foundation’s business office is located at 809 north 1500 west,\r\n",
            "salt lake city, ut 84116, (801) 596-1887. email contact links and up\r\n",
            "to date contact information can be found at the foundation’s website\r\n",
            "and official page at www.gutenberg.org/contact\r\n",
            "\r\n",
            "section 4. information about donations to the project gutenberg\r\n",
            "literary archive foundation\r\n",
            "\r\n",
            "project gutenberg™ depends upon and cannot survive without widespread\r\n",
            "public support and donations to carry out its mission of\r\n",
            "increasing the number of public domain and licensed works that can be\r\n",
            "freely distributed in machine-readable form accessible by the widest\r\n",
            "array of equipment including outdated equipment. many small donations\r\n",
            "($1 to $5,000) are particularly important to maintaining tax exempt\r\n",
            "status with the irs.\r\n",
            "\r\n",
            "the foundation is committed to complying with the laws regulating\r\n",
            "charities and charitable donations in all 50 states of the united\r\n",
            "states. compliance requirements are not uniform and it takes a\r\n",
            "considerable effort, much paperwork and many fees to meet and keep up\r\n",
            "with these requirements. we do not solicit donations in locations\r\n",
            "where we have not received written confirmation of compliance. to send\r\n",
            "donations or determine the status of compliance for any particular state\r\n",
            "visit www.gutenberg.org/donate.\r\n",
            "\r\n",
            "while we cannot and do not solicit contributions from states where we\r\n",
            "have not met the solicitation requirements, we know of no prohibition\r\n",
            "against accepting unsolicited donations from donors in such states who\r\n",
            "approach us with offers to donate.\r\n",
            "\r\n",
            "international donations are gratefully accepted, but we cannot make\r\n",
            "any statements concerning tax treatment of donations received from\r\n",
            "outside the united states. u.s. laws alone swamp our small staff.\r\n",
            "\r\n",
            "please check the project gutenberg web pages for current donation\r\n",
            "methods and addresses. donations are accepted in a number of other\r\n",
            "ways including checks, online payments and credit card donations. to\r\n",
            "donate, please visit: www.gutenberg.org/donate.\r\n",
            "\r\n",
            "section 5. general information about project gutenberg™ electronic works\r\n",
            "\r\n",
            "professor michael s. hart was the originator of the project\r\n",
            "gutenberg™ concept of a library of electronic works that could be\r\n",
            "freely shared with anyone. for forty years, he produced and\r\n",
            "distributed project gutenberg™ ebooks with only a loose network of\r\n",
            "volunteer support.\r\n",
            "\r\n",
            "project gutenberg™ ebooks are often created from several printed\r\n",
            "editions, all of which are confirmed as not protected by copyright in\r\n",
            "the u.s. unless a copyright notice is included. thus, we do not\r\n",
            "necessarily keep ebooks in compliance with any particular paper\r\n",
            "edition.\r\n",
            "\r\n",
            "most people start at our website which has the main pg search\r\n",
            "facility: www.gutenberg.org.\r\n",
            "\r\n",
            "this website includes information about project gutenberg™,\r\n",
            "including how to make donations to the project gutenberg literary\r\n",
            "archive foundation, how to help produce our new ebooks, and how to\r\n",
            "subscribe to our email newsletter to hear about new ebooks.\r\n",
            "\r\n",
            "\r\n",
            "\n",
            "File size: 3.20 MB\n",
            "File size: 3,359,652 bytes\n"
          ]
        }
      ],
      "source": [
        "# URL of the text file\n",
        "url = 'https://www.gutenberg.org/cache/epub/2600/pg2600.txt'\n",
        "\n",
        "try:\n",
        "    # Fetch the file\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Check if request was successful\n",
        "\n",
        "    # Decode the content with UTF-8 and load into a file-like object\n",
        "    text_file = io.StringIO(response.content.decode('utf-8'))\n",
        "\n",
        "    # Read the content\n",
        "    text1 = text_file.read().lower()\n",
        "\n",
        "    text = text1[8300:]\n",
        "\n",
        "\n",
        "    # Define the number of characters you want to remove from the end\n",
        "    x = 18830  # characters to remove off end\n",
        "\n",
        "    # Remove the last x characters\n",
        "    trimmed_text = text[:-x] if x < len(text) else \"\"\n",
        "    trimmed_part = text[-x:] if x < len(text) else text  # The part that was removed\n",
        "\n",
        "    # Print or process the trimmed part and the remaining text\n",
        "    print(\"Trimmed Part (last\", x, \"characters):\\n\", trimmed_part)\n",
        "\n",
        "\n",
        "    # Print or use the trimmed text\n",
        "\n",
        "\n",
        "    # Step 1: Data Preparation\n",
        "\n",
        "\n",
        "    # Basic text cleaning to remove unwanted characters\n",
        "    # We’re keeping only letters and basic punctuation for simplicity\n",
        "\n",
        "    text = re.sub(r'[^a-zA-Z ,.!?]', '', trimmed_text)\n",
        "\n",
        "     # Get the file size in bytes, each Character depending on if it sspecial\n",
        "    file_size_bytes = len(response.content)\n",
        "\n",
        "    # megabyte = 1,048,576 bytes.\n",
        "    file_size_mb = file_size_bytes / (1024 ** 2)\n",
        "\n",
        "    # Print file size in MB and Bytes\n",
        "    # each character has on average 1 byte, but special characters and symbols can have up to 4. This is just for UTF-8 encoded text.\n",
        "    print(f\"File size: {file_size_mb:.2f} MB\")\n",
        "    print(f\"File size: {file_size_bytes:,} bytes\")\n",
        "\n",
        "    # Process or print content\n",
        "    # print(content)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(\"Error accessing the file:\", e)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Print or process `text` to verify\n",
        "print(text[:500])  # Print the first 500 characters to verify\n",
        "\n",
        "# Now, you can proceed to tokenize and prepare sequences with `text`"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4ROlpYsoC_5",
        "outputId": "fff12cfd-3080-4413-c801-a39976814641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "well, prince, so genoa and lucca are now just family estates of thebuonapartes. but i warn you, if you dont tell me that this means war,if you still try to defend the infamies and horrors perpetrated by thatantichristi really believe he is antichristi will have nothingmore to do with you and you are no longer my friend, no longer myfaithful slave, as you call yourself! but how do you do? i see ihave frightened yousit down and tell me all the news.it was in july, , and the speaker was the wellkno\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLHl69yNb7q9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62baaee3-a140-4a5f-d8c9-7fc0c2909aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Characters: [' ', '!', ',', '.', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "Character to Integer Mapping: {' ': 0, '!': 1, ',': 2, '.': 3, '?': 4, 'a': 5, 'b': 6, 'c': 7, 'd': 8, 'e': 9, 'f': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'n': 18, 'o': 19, 'p': 20, 'q': 21, 'r': 22, 's': 23, 't': 24, 'u': 25, 'v': 26, 'w': 27, 'x': 28, 'y': 29, 'z': 30}\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Character Mapping\n",
        "\n",
        "# Create a sorted list of unique characters in the text.\n",
        "# We do this because computers cannot understand language, only numbers.\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {char: i for i, char in enumerate(chars)}  # map characters to integers\n",
        "int_to_char = {i: char for i, char in enumerate(chars)}  # map integers back to characters\n",
        "\n",
        "# Display the mappings to understand the character encoding\n",
        "print(f\"Unique Characters: {chars}\")\n",
        "print(f\"Character to Integer Mapping: {char_to_int}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Sequence Creation\n",
        "\n",
        "# Sequence length, i.e., how many characters the model will look back to predict the next one\n",
        "sequence_length = 150\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "\n",
        "\n",
        "# Loop to create sequences and the corresponding target character\n",
        "for i in range(0, len(text) - sequence_length):\n",
        "    sequences.append(text[i:i + sequence_length])\n",
        "    next_chars.append(text[i + sequence_length])\n",
        "\n",
        "print(f\"Total Sequences Created: {len(sequences)}\")\n",
        "# total sequences calculated as follows ,      (number of total character - sequence length) / stride\n",
        "\n",
        "\n",
        "\n",
        "# Convert the characters in sequences and next_chars to integers\n",
        "X = np.zeros((len(sequences), sequence_length), dtype=np.int32)\n",
        "y = np.zeros((len(sequences)), dtype=np.int32)\n",
        "\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    X[i] = [char_to_int[char] for char in seq]\n",
        "    y[i] = char_to_int[next_chars[i]]\n",
        "\n",
        "# Convert y to categorical format for prediction\n",
        "y = to_categorical(y, num_classes=len(chars))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLe-JWVphGlh",
        "outputId": "428e8596-e467-4002-c63f-46e559e2b842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences Created: 3092071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5xXnAyWNjdIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, BatchNormalization, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Initialize an enhanced sequential model\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1. Embedding layer to learn representations of characters\n",
        "model.add(Embedding(input_dim=len(chars), output_dim=128, input_length=sequence_length))\n",
        "\n",
        "# 2. First Bidirectional LSTM layer with 256 units\n",
        "# Bidirectional LSTM helps capture context in both forward and backward directions\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(Dropout(0.3))  # Dropout to reduce overfitting\n",
        "\n",
        "# 3. Batch normalization for stable training\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4. Second Bidirectional LSTM layer with 512 units for deeper learning\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=True)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5. Third LSTM layer without Bidirectional; fewer units (e.g., 256) to condense information\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# 6. Additional Dense layer to capture more complex relationships after LSTM layers\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# 7. Output Dense layer with softmax activation for character prediction\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "# Compile the model with a clipped Adam optimizer and a learning rate scheduler\n",
        "model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler to reduce learning rate if there's no improvement\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-5)\n",
        "\n",
        "# Display the model architecture for review\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "0a8X1AvWGCxF",
        "outputId": "026f9420-a2df-436e-9bb1-7a433dfd66b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                       │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# Adjust callbacks to monitor validation loss\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=2,  # Slightly increase patience to avoid early stopping too soon\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Convert y to categorical labels\n",
        "# y = to_categorical(y, num_classes=len(chars))\n",
        "\n",
        "# Split data: 80% train, 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display shapes for verification\n",
        "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape, y_test.shape)\n",
        "\n",
        "# Now you can train the model with the 80-20 split\\\n",
        "\n",
        "# Increased patience to allow for small fluctuations in validation loss\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(X_test, y_test),  # Validate on the 20% test split\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")\n",
        "\n",
        "# accuracy far better than random (3.23%) means we have a working model.\n",
        "# (number of predicted chars (1) / number of total unique character choices (31) = 1/31 = 3.23%)\n",
        "# Even an accuracy of 50% would mean we are only wrong half the time,\n",
        "# as opposed to being wrong 30 out of 31 times with random accuracy.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD40n4y1Go3V",
        "outputId": "b6626eba-018d-4dd7-8f35-84ef8d3580cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (2473596, 150) (2473596, 31)\n",
            "Testing data shape: (618400, 150) (618400, 31)\n",
            "Epoch 1/10\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4100 - loss: 2.0063\n",
            "Epoch 1: val_loss improved from inf to 1.52762, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1801s\u001b[0m 47ms/step - accuracy: 0.4100 - loss: 2.0063 - val_accuracy: 0.5345 - val_loss: 1.5276 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5135 - loss: 1.6277\n",
            "Epoch 2: val_loss improved from 1.52762 to 1.45139, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1802s\u001b[0m 47ms/step - accuracy: 0.5135 - loss: 1.6277 - val_accuracy: 0.5570 - val_loss: 1.4514 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m38649/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5309 - loss: 1.5643\n",
            "Epoch 3: val_loss improved from 1.45139 to 1.43819, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1803s\u001b[0m 47ms/step - accuracy: 0.5309 - loss: 1.5643 - val_accuracy: 0.5611 - val_loss: 1.4382 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5261 - loss: 1.5814\n",
            "Epoch 4: val_loss improved from 1.43819 to 1.43261, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1804s\u001b[0m 47ms/step - accuracy: 0.5261 - loss: 1.5814 - val_accuracy: 0.5630 - val_loss: 1.4326 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5326 - loss: 1.5588\n",
            "Epoch 5: val_loss improved from 1.43261 to 1.42602, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1804s\u001b[0m 47ms/step - accuracy: 0.5326 - loss: 1.5588 - val_accuracy: 0.5646 - val_loss: 1.4260 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5312 - loss: 1.5650\n",
            "Epoch 6: val_loss did not improve from 1.42602\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1803s\u001b[0m 47ms/step - accuracy: 0.5312 - loss: 1.5650 - val_accuracy: 0.5611 - val_loss: 1.4368 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m38649/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5249 - loss: 1.5864\n",
            "Epoch 7: val_loss improved from 1.42602 to 1.39618, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1804s\u001b[0m 47ms/step - accuracy: 0.5249 - loss: 1.5864 - val_accuracy: 0.5730 - val_loss: 1.3962 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5410 - loss: 1.5313\n",
            "Epoch 8: val_loss improved from 1.39618 to 1.38359, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1804s\u001b[0m 47ms/step - accuracy: 0.5410 - loss: 1.5313 - val_accuracy: 0.5762 - val_loss: 1.3836 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5486 - loss: 1.5042\n",
            "Epoch 9: val_loss improved from 1.38359 to 1.36875, saving model to best_model.keras\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1804s\u001b[0m 47ms/step - accuracy: 0.5486 - loss: 1.5042 - val_accuracy: 0.5813 - val_loss: 1.3687 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m38649/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5511 - loss: 1.4931\n",
            "Epoch 10: val_loss did not improve from 1.36875\n",
            "\u001b[1m38650/38650\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1804s\u001b[0m 47ms/step - accuracy: 0.5511 - loss: 1.4931 - val_accuracy: 0.5729 - val_loss: 1.3958 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 9.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f00d414d9f0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import Parallel, delayed\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Save the model as a pickle in a file\n",
        "joblib.dump(model, 'best_model_LSTM.pkl')\n",
        "\n",
        "# Load the model from the file\n",
        "model_LSTM = joblib.load('best_model_LSTM.pkl')\n",
        "\n",
        "# Use the loaded model to make predictions\n"
      ],
      "metadata": {
        "id": "tKSfl_cfv0Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "5jmSg0WWu5rN",
        "outputId": "9915c253-b4c6-428f-b0b9-3a4e4a386ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m3,968\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m788,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m4,198,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m1,311,744\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │           \u001b[38;5;34m7,967\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,744</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,967</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,141,343\u001b[0m (73.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,141,343</span> (73.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,379,423\u001b[0m (24.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,379,423</span> (24.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,072\u001b[0m (12.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,072</span> (12.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m12,758,848\u001b[0m (48.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,758,848</span> (48.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3caWfrZvyLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_text(model, seed_text, num_chars=150, temperature=0.5):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(num_chars):\n",
        "        input_seq = np.array([char_to_int[char] for char in seed_text]).reshape(1, -1)\n",
        "        predictions = model.predict(input_seq, verbose=0)[0]\n",
        "\n",
        "        # Adjust predictions by temperature\n",
        "        predictions = np.log(predictions + 1e-10) / temperature\n",
        "        predictions = np.exp(predictions) / np.sum(np.exp(predictions))\n",
        "\n",
        "        # Sample the next character based on adjusted probabilities\n",
        "        next_index = np.random.choice(len(predictions), p=predictions)\n",
        "        next_char = int_to_char[next_index]\n",
        "\n",
        "        generated_text += next_char\n",
        "        seed_text = seed_text[1:] + next_char\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "\n",
        "\n",
        "# Testing the generation function with a seed text\n",
        "seed_text = text[:sequence_length]  # Starting text to kick off the prediction\n",
        "generated_text = generate_text(model, seed_text)\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW5pftNQJAPl",
        "outputId": "f52f5b11-bcc0-439f-a0d9-45e021b843ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "well, prince, so genoa and lucca are now just family estates of thebuonaparte went in the countess. but it was could be an austrian regiment was noticed the staff great respectful to the princess startled in the soldiers. she\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOmvEDd5mi0M7DL0HQP/nFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}